Databricks
==========

Sparkflows has a processor that allows you to connect with Databricks table and DBFS file system.

Read Databricks Table in Workflow
---------------------------------

In the workflow, use the processor **Read Databricks Table**. It allows you to read tables from Databricks.

Then, use the other processors in Fire for processing the data read from the Databricks Table, as shown below.

Workflow
++++++++

 .. figure:: ../../_assets/configuration/Read-Databricks-Table-WF.png
    :alt: Databricks
    :width: 40%

**Processor Configurations for ReadDatabricksTable**
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Configure the ReadDatabricksTable Processor by defining the following details, as shown below:
 
 .. figure:: ../../_assets/configuration/databricks-editor.PNG
    :alt: Databricks
    :width: 85%


* **DATABRICKS DATABASE:** Click on **BROWSE STUDIO DB** and select the desired database.
* **DATABRICKS TABLE:** Click on **BROWSE STUDIO TABLE** and select the desired table.



**Refresh Schema for Processor ReadDatabricksTable**
+++++++++++++++++++++++++++++++++++++++++++++++++++++
 
 .. figure:: ../../_assets/configuration/databricks-refreshschema.PNG
    :alt: Databricks
    :width: 85% 

**Processor Executions for ReadDatabricksTable**
+++++++++++++++++++++++++++++++++++++++++++++++++++++

 .. figure:: ../../_assets/configuration/databrcks-interactiveexecutions.PNG
    :alt: Databricks
    :width: 85%

**Databricks Workflow Execution**
+++++++++++++++++++++++++++++++++++++

Below is the **output** generated by executing the above workflow, which reads data from a Databricks table.

 .. figure:: ../../_assets/configuration/databricks-workflowexecutions.PNG
    :alt: Databricks
    :width: 85%



Save Databricks Table
-------------------
In the workflow, use the processor **SaveDatabricksTable**. It allows you to save data to Databricks tables.

Below is a workflow which writes data to the Databricks table.

Workflow
++++++++

 .. figure:: ../../_assets/configuration/Write-databricks-WF.png
    :alt: Databricks
    :width: 40%

**Processor Configurations for SaveDatabricksTable**
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Configure the SaveDatabricksTable Processor by defining the following details:

 .. figure:: ../../_assets/configuration/savedatabricks_configuration.PNG
   :alt: Databricks
   :width: 85%


* **DATABRICKS DATABASE:** Click on **BROWSE STUDIO DB** and select desired database.
* **DATABRICKS TABLE:** Click on **BROWSE STUDIO TABLE** and select desired table.
* **FORMAT:** Choose **CSV**, **JSON**, **Parquet**, or **ORC** file formats from the dropdown. The tables can be saved into these file formats.
* **SAVE MODE:** Choose the modes **Append**, **Overwrite**, **ErrorIfExists** or **Ignore** from the dropdown menu.




**Databricks Workflow Execution**
+++++++++++++++++++++++++++++++++++

Below is the **output** of executing the above workflow, which saves the data to a Databricks table.

 .. figure:: ../../_assets/configuration/savedatabricksworkflo_wexecution.PNG
    :alt: Databricks
    :width: 85%


Verify the Table


 .. figure:: ../../_assets/configuration/databrickstable_saved.PNG
    :alt: Databricks
    :width: 85%
   
   
**File Formats**
++++++++++++++++++

* Tables can be saved into **CSV**, **JSON**, **Parquet** and **ORC** file formats.

* If the file format is not specified, the data in tables is stored in **Parquet** format **by default**.

