Feature Selection
=================

In machine learning and statistics, feature selection, also known as variable selection, attribute selection, or variable subset selection, is the process of selecting a subset of relevant features (variables, predictors) for use in model construction. Feature selection techniques are used for several reasons like:

- to have simplification of models to make them easier to interpret by researchers/users.
- to have shorter training times.
- to avoid the curse of dimensionality.
- to have enhanced generalization by reducing overfitting (formally, reduction of variance).

More information on Feature Selection can be found at: https://en.wikipedia.org/wiki/Feature_selection  


Apache Spark has the following Feature Selectors. Fire Insights provides them as Processors to be easily used in the workflows.


Feature Selection Processors in Fire Insights
----------------------------------------------

.. list-table:: Apache Spark based Feature Selection Processors in Fire Insights
   :widths: 20 50
   :header-rows: 1

   * - Title
     - Description
   * - VectorSlicer
     - VectorSlicer is a transformer that takes a feature vector and outputs a new feature vector with a sub-array of the original features. It is useful for extracting features from a vector column. VectorSlicer accepts a vector column with specified indices, then outputs a new vector column whose values are selected via those indices.
   * - RFormula
     - RFormula selects columns specified by an R model formula. RFormula produces a vector column of features and a double or string column of labels. Like when formulas are used in R for linear regression, string input columns will be one-hot encoded, and numeric columns will be cast to doubles. If the label column is of type string, it will be first transformed to double with StringIndexer. If the label column does not exist in the DataFrame, the output label column will be created from the specified response variable in the formula.

   * - ChiSqSelector
     - ChiSqSelector stands for Chi-Squared feature selection. It operates on labeled data with categorical features. ChiSqSelector uses the Chi-Squared test of independence to decide which features to choose. It supports five selection methods: numTopFeatures, percentile, fpr, fdr, fwe.

More details regarding the Feature Selectors in Spark can be found at: https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#feature

VectorSlicer
------------

VectorSlicer is a transformer that takes a feature vector and outputs a new feature vector with a sub-array of the original features. It is useful for extracting features from a vector column.
VectorSlicer accepts a vector column with specified indices, then outputs a new vector column whose values are selected via those indices. There are two types of indices, namely:

**Integer indices** that represent the indices into the vector, setIndices().

**String indices** that represent the names of features into the vector, setNames(). This requires the vector column to have an AttributeGroup since the implementation matches on the name field of an Attribute.

Specification by integer and string are both acceptable. Moreover, you can use integer index and string name simultaneously. At least, one feature must be selected. Duplicate features are not allowed, so there can be no overlap between selected indices and names. Note that if names of features are selected, an exception will be thrown if empty input attributes are encountered.

RFormula
--------

RFormula selects columns specified by an R model formula. Currently Spark supports a limited subset of the R operators, including ‘~’, ‘.’, ‘:’, ‘+’, and ‘-‘. The basic operators are:

- ~ separate target and terms.
- + concat terms, “+ 0” means removing intercept.
- - remove a term, “- 1” means removing intercept.
- : interaction (multiplication for numeric values, or binarized categorical values).
- . all columns except target.

Suppose, a and b are double columns, we use the following simple examples to illustrate the effect of RFormula:

- y ~ a + b means model y ~ w0 + w1 * a + w2 * b where w0 is the intercept and w1, w2 are coefficients.
-  y ~ a + b + a:b - 1 means model y ~ w1 * a + w2 * b + w3 * a * b where w1, w2, w3 are coefficients.
RFormula produces a vector column of features and a double or string column of label. Like when formulas are used in R for linear regression, string input columns will be one-hot encoded, and numeric columns will be cast to doubles. If the label column is of type string, it will be first transformed to double with StringIndexer. If the label column does not exist in the DataFrame, the output label column will be created from the specified response variable in the formula.

ChiSqSelector
--------------

ChiSqSelector stands for Chi-Squared feature selection. It operates on labeled data with categorical features. ChiSqSelector uses the Chi-Squared test of independence to decide which features to choose. It supports five selection methods namely, numTopFeatures, percentile, fpr, fdr, and fwe.

- **numTopFeatures:** chooses a fixed number of top features according to a chi-squared test. This is akin to yielding the features with the most predictive power.
- **percentile:** is similar to numTopFeatures but chooses a fraction of all features instead of a fixed number. 
- **fpr:** chooses all features whose p-values are below a threshold, thus controlling the false positive rate of selection. 
- **fdr:** uses the Benjamini-Hochberg procedure to choose all features whose false discovery rate is below a threshold.
- **fwe:** chooses all features whose p-values are below a threshold. ::

The threshold is scaled by 1/numFeatures, thus controlling the family-wise error rate of selection. By default, the selection method is numTopFeatures, with the default number of top features set to 50. The user can choose a selection method using setSelectorType.
